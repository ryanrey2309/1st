{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srTnsl3hq6Hx"
      },
      "outputs": [],
      "source": [
        "# Full notebook script: baseline preserved + added cleaning, viz, outlier analysis, tuning\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# ==========================================\n",
        "# 1. USER CONFIGURATION (EDIT THIS PART ONLY)\n",
        "# ==========================================\n",
        "TRAIN_PATH = \"/kaggle/input/ai-201-b-mse-2-aiml-c/train.csv\"\n",
        "TEST_PATH = \"/kaggle/input/ai-201-b-mse-2-aiml-c/test.csv\"\n",
        "TARGET_COL = \"NObeyesdad\"\n",
        "ID_COL = \"id\"\n",
        "OUTPUT_FILE = \"submission.csv\"\n",
        "# Toggle heavy steps (set False to skip long operations)\n",
        "DO_PLOTTING = True\n",
        "DO_OUTLIER_CAP = False  # If True, numeric outliers will be capped using IQR method\n",
        "DO_HYPERPARAM_TUNING = True  # If True, run RandomizedSearchCV (can be slow)\n",
        "RANDOM_STATE = 42\n",
        "# ==========================================\n",
        "\n",
        "# 2. Load Data\n",
        "print(\"Loading data...\")\n",
        "train_data = pd.read_csv(TRAIN_PATH)\n",
        "test_data = pd.read_csv(TEST_PATH)\n",
        "\n",
        "print(f\"Train shape: {train_data.shape}\")\n",
        "print(f\"Test shape: {test_data.shape}\")\n",
        "\n",
        "# Keep test IDs for submission\n",
        "test_ids = test_data[ID_COL] if ID_COL in test_data.columns else None\n",
        "\n",
        "# Drop ID cols from feature tables to match previous logic\n",
        "if ID_COL in train_data.columns:\n",
        "    train_data = train_data.drop(columns=[ID_COL])\n",
        "if ID_COL in test_data.columns:\n",
        "    test_data = test_data.drop(columns=[ID_COL])\n",
        "\n",
        "# -------------------------\n",
        "# DATA CLEANING (10 marks)\n",
        "# -------------------------\n",
        "print(\"\\n=== Data Cleaning ===\")\n",
        "\n",
        "# 1) Basic info\n",
        "print(\"\\nTrain info:\")\n",
        "print(train_data.info())\n",
        "print(\"\\nTest info:\")\n",
        "print(test_data.info())\n",
        "\n",
        "# 2) Duplicates\n",
        "train_dups = train_data.duplicated().sum()\n",
        "print(f\"\\nDuplicate rows in train: {train_dups}\")\n",
        "if train_dups > 0:\n",
        "    print(\"Dropping duplicate rows from train.\")\n",
        "    train_data = train_data.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "# 3) Missing value summary\n",
        "print(\"\\nMissing values (train):\")\n",
        "print(train_data.isnull().sum()[train_data.isnull().sum() > 0])\n",
        "print(\"\\nMissing values (test):\")\n",
        "print(test_data.isnull().sum()[test_data.isnull().sum() > 0])\n",
        "\n",
        "# 4) Inconsistent categorical values (basic check)\n",
        "cat_columns_guess = train_data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "print(f\"\\nDetected categorical columns for checking consistency: {cat_columns_guess}\")\n",
        "for c in cat_columns_guess:\n",
        "    unique_vals = train_data[c].unique()\n",
        "    if len(unique_vals) <= 20:\n",
        "        print(f\" Column `{c}` unique values: {unique_vals}\")\n",
        "\n",
        "# 5) Target distribution check\n",
        "if TARGET_COL in train_data.columns:\n",
        "    print(\"\\nTarget distribution:\")\n",
        "    print(train_data[TARGET_COL].value_counts(normalize=True))\n",
        "else:\n",
        "    raise ValueError(f\"Target column {TARGET_COL} not found in train data.\")\n",
        "\n",
        "# Keep a copy for visualization without destructive changes\n",
        "train_viz = train_data.copy()\n",
        "\n",
        "# -------------------------\n",
        "# PREPROCESSING (kept as logic)\n",
        "# -------------------------\n",
        "# Separate X and y as before (preserve original logic)\n",
        "X = train_data.drop(columns=[TARGET_COL])\n",
        "y = train_data[TARGET_COL]\n",
        "\n",
        "# Dynamic feature detection (same as original)\n",
        "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "num_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "print(f\"\\nDetected {len(cat_cols)} categorical columns: {cat_cols}\")\n",
        "print(f\"Detected {len(num_cols)} numerical columns: {num_cols}\")\n",
        "\n",
        "# -------------------------\n",
        "# OUTLIER ANALYSIS & HANDLING (10 marks)\n",
        "# -------------------------\n",
        "print(\"\\n=== Outlier Analysis ===\")\n",
        "if DO_PLOTTING:\n",
        "    # Histograms for numeric columns (small figure for speed; comment/uncomment as needed)\n",
        "    n_num = len(num_cols)\n",
        "    if n_num > 0:\n",
        "        ncols = 3\n",
        "        nrows = (n_num + ncols - 1) // ncols\n",
        "        plt.figure(figsize=(5 * ncols, 4 * nrows))\n",
        "        for i, col in enumerate(num_cols, 1):\n",
        "            plt.subplot(nrows, ncols, i)\n",
        "            sns.histplot(train_viz[col].dropna(), kde=True)\n",
        "            plt.title(col)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Boxplots to visualize outliers\n",
        "    if n_num > 0:\n",
        "        plt.figure(figsize=(5 * ncols, 4 * nrows))\n",
        "        for i, col in enumerate(num_cols, 1):\n",
        "            plt.subplot(nrows, ncols, i)\n",
        "            sns.boxplot(x=train_viz[col].dropna())\n",
        "            plt.title(f\"Boxplot: {col}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Correlation heatmap for numerical features\n",
        "    if n_num > 1:\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        corr = train_viz[num_cols].corr()\n",
        "        sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
        "        plt.title(\"Correlation matrix (numeric features)\")\n",
        "        plt.show()\n",
        "\n",
        "    # Countplots for categorical features (top categories only)\n",
        "    for c in cat_cols:\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        sns.countplot(y=c, data=train_viz, order=train_viz[c].value_counts().index[:20])\n",
        "        plt.title(f\"Counts for {c}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# -------------- IQR based outlier detection (non-destructive)\n",
        "outlier_summary = {}\n",
        "for col in num_cols:\n",
        "    q1 = train_viz[col].quantile(0.25)\n",
        "    q3 = train_viz[col].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower = q1 - 1.5 * iqr\n",
        "    upper = q3 + 1.5 * iqr\n",
        "    n_lower = (train_viz[col] < lower).sum()\n",
        "    n_upper = (train_viz[col] > upper).sum()\n",
        "    outlier_summary[col] = {\"lower\": lower, \"upper\": upper, \"n_lower\": int(n_lower), \"n_upper\": int(n_upper)}\n",
        "print(\"\\nOutlier summary (IQR method):\")\n",
        "for col, s in outlier_summary.items():\n",
        "    print(f\" {col}: below {s['n_lower']}, above {s['n_upper']}\")\n",
        "\n",
        "# Optionally cap outliers (explicitly controlled by DO_OUTLIER_CAP)\n",
        "if DO_OUTLIER_CAP:\n",
        "    print(\"\\nCapping numeric outliers using IQR thresholds (applied to both train/test).\")\n",
        "    for col, s in outlier_summary.items():\n",
        "        lower, upper = s['lower'], s['upper']\n",
        "        # Cap in X (train features) and in test_data numeric cols\n",
        "        X[col] = X[col].clip(lower=lower, upper=upper)\n",
        "        if col in test_data.columns:\n",
        "            test_data[col] = test_data[col].clip(lower=lower, upper=upper)\n",
        "\n",
        "# -------------------------\n",
        "# MISSING VALUES IMPUTATION (kept logic but documented)\n",
        "# -------------------------\n",
        "print(\"\\n=== Missing Value Imputation ===\")\n",
        "# Numeric imputation\n",
        "if num_cols:\n",
        "    mean_vals = X[num_cols].mean()\n",
        "    print(\"Numeric mean fill (per column):\")\n",
        "    print(mean_vals)\n",
        "    X[num_cols] = X[num_cols].fillna(mean_vals)\n",
        "    test_data[num_cols] = test_data[num_cols].fillna(mean_vals)\n",
        "\n",
        "# Categorical imputation\n",
        "if cat_cols:\n",
        "    mode_vals = X[cat_cols].mode().iloc[0]\n",
        "    print(\"Categorical mode fill (per column):\")\n",
        "    print(mode_vals.to_dict())\n",
        "    X[cat_cols] = X[cat_cols].fillna(mode_vals)\n",
        "    test_data[cat_cols] = test_data[cat_cols].fillna(mode_vals)\n",
        "\n",
        "# -------------------------\n",
        "# VISUAL CHECK AFTER IMPUTATION\n",
        "# -------------------------\n",
        "print(\"\\nAfter imputation, missing values (train):\")\n",
        "print(X.isnull().sum()[X.isnull().sum() > 0])\n",
        "\n",
        "# -------------------------\n",
        "# DEFINE PREPROCESSOR (kept logic)\n",
        "# -------------------------\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_cols),\n",
        "    ('num', StandardScaler(), num_cols)\n",
        "])\n",
        "\n",
        "# -------------------------\n",
        "# TRAIN/VALIDATION SPLIT (kept logic)\n",
        "# -------------------------\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3,\n",
        "                                                  random_state=RANDOM_STATE, stratify=y)\n",
        "\n",
        "# Fit preprocessor (kept)\n",
        "print(\"\\nTransforming data (fit preprocessor on train)...\")\n",
        "X_train_pre = preprocessor.fit_transform(X_train)\n",
        "X_val_pre = preprocessor.transform(X_val)\n",
        "test_data_pre = preprocessor.transform(test_data)\n",
        "\n",
        "# -------------------------\n",
        "# LABEL ENCODING (kept)\n",
        "# -------------------------\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_val_enc = le.transform(y_val)\n",
        "\n",
        "# -------------------------\n",
        "# BASELINE MODEL (kept)\n",
        "# -------------------------\n",
        "print(\"\\n=== Baseline RandomForest Training ===\")\n",
        "baseline_rfc = RandomForestClassifier(n_estimators=1000, random_state=RANDOM_STATE,\n",
        "                                      class_weight='balanced', n_jobs=-1)\n",
        "baseline_rfc.fit(X_train_pre, y_train_enc)\n",
        "\n",
        "# Baseline predictions\n",
        "train_proba_base = baseline_rfc.predict_proba(X_train_pre)\n",
        "val_proba_base = baseline_rfc.predict_proba(X_val_pre)\n",
        "\n",
        "# Metrics for baseline\n",
        "n_classes_base = train_proba_base.shape[1]\n",
        "if n_classes_base == 2:\n",
        "    roc_train_base = roc_auc_score(y_train_enc, train_proba_base[:, 1])\n",
        "    roc_val_base = roc_auc_score(y_val_enc, val_proba_base[:, 1])\n",
        "else:\n",
        "    roc_train_base = roc_auc_score(y_train_enc, train_proba_base, multi_class='ovr', average='macro')\n",
        "    roc_val_base = roc_auc_score(y_val_enc, val_proba_base, multi_class='ovr', average='macro')\n",
        "\n",
        "loss_train_base = log_loss(y_train_enc, train_proba_base)\n",
        "loss_val_base = log_loss(y_val_enc, val_proba_base)\n",
        "\n",
        "print(f\"Baseline Training ROC AUC: {roc_train_base:.4f}\")\n",
        "print(f\"Baseline Validation ROC AUC: {roc_val_base:.4f}\")\n",
        "print(f\"Baseline Training Log Loss: {loss_train_base:.4f}\")\n",
        "print(f\"Baseline Validation Log Loss: {loss_val_base:.4f}\")\n",
        "\n",
        "# -------------------------\n",
        "# HYPERPARAMETER TUNING (10 marks)\n",
        "# -------------------------\n",
        "tuned_rfc = None\n",
        "if DO_HYPERPARAM_TUNING:\n",
        "    print(\"\\n=== Hyperparameter Tuning (RandomizedSearchCV) ===\")\n",
        "    # Parameter grid for RandomizedSearch (typical ranges for RF)\n",
        "    param_dist = {\n",
        "        \"n_estimators\": [200, 500, 800, 1000],\n",
        "        \"max_depth\": [None, 6, 10, 15, 20],\n",
        "        \"min_samples_split\": [2, 5, 8, 10],\n",
        "        \"min_samples_leaf\": [1, 2, 4, 6],\n",
        "        \"max_features\": [\"auto\", \"sqrt\", 0.2, 0.5]\n",
        "    }\n",
        "\n",
        "    rnd_search = RandomizedSearchCV(\n",
        "        estimator=RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced', n_jobs=-1),\n",
        "        param_distributions=param_dist,\n",
        "        n_iter=25,\n",
        "        scoring='roc_auc_ovr' if n_classes_base > 2 else 'roc_auc',\n",
        "        cv=3,\n",
        "        verbose=1,\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    rnd_search.fit(X_train_pre, y_train_enc)\n",
        "    print(\"Best params found:\")\n",
        "    print(rnd_search.best_params_)\n",
        "    print(f\"Best CV score: {rnd_search.best_score_:.4f}\")\n",
        "\n",
        "    tuned_rfc = rnd_search.best_estimator_\n",
        "\n",
        "    # Evaluate tuned model on train & val sets\n",
        "    train_proba_tuned = tuned_rfc.predict_proba(X_train_pre)\n",
        "    val_proba_tuned = tuned_rfc.predict_proba(X_val_pre)\n",
        "\n",
        "    if n_classes_base == 2:\n",
        "        roc_train_tuned = roc_auc_score(y_train_enc, train_proba_tuned[:, 1])\n",
        "        roc_val_tuned = roc_auc_score(y_val_enc, val_proba_tuned[:, 1])\n",
        "    else:\n",
        "        roc_train_tuned = roc_auc_score(y_train_enc, train_proba_tuned, multi_class='ovr', average='macro')\n",
        "        roc_val_tuned = roc_auc_score(y_val_enc, val_proba_tuned, multi_class='ovr', average='macro')\n",
        "\n",
        "    loss_train_tuned = log_loss(y_train_enc, train_proba_tuned)\n",
        "    loss_val_tuned = log_loss(y_val_enc, val_proba_tuned)\n",
        "\n",
        "    print(\"\\nTuned model metrics:\")\n",
        "    print(f\"Tuned Training ROC AUC: {roc_train_tuned:.4f}\")\n",
        "    print(f\"Tuned Validation ROC AUC: {roc_val_tuned:.4f}\")\n",
        "    print(f\"Tuned Training Log Loss: {loss_train_tuned:.4f}\")\n",
        "    print(f\"Tuned Validation Log Loss: {loss_val_tuned:.4f}\")\n",
        "else:\n",
        "    print(\"\\nHyperparameter tuning skipped by configuration.\")\n",
        "\n",
        "# -------------------------\n",
        "# OPTION: choose model for submission\n",
        "# We preserve your original logic: baseline_rfc is the trained model used by default.\n",
        "# If you want to use the tuned model for submission, set `use_tuned=True` below.\n",
        "# -------------------------\n",
        "use_tuned = True if (DO_HYPERPARAM_TUNING and tuned_rfc is not None) else False\n",
        "model_for_submission = tuned_rfc if use_tuned else baseline_rfc\n",
        "if use_tuned:\n",
        "    print(\"\\nUsing TUNED model for submission.\")\n",
        "else:\n",
        "    print(\"\\nUsing BASELINE model for submission (same as original logic).\")\n",
        "\n",
        "# -------------------------\n",
        "# OPTIONAL: ROC CURVE PLOT (small)\n",
        "# -------------------------\n",
        "if DO_PLOTTING:\n",
        "    try:\n",
        "        from sklearn.metrics import RocCurveDisplay\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        if n_classes_base == 2:\n",
        "            RocCurveDisplay.from_estimator(model_for_submission, X_val_pre, y_val_enc)\n",
        "            plt.title(\"ROC Curve (Validation)\")\n",
        "            plt.show()\n",
        "        else:\n",
        "            # Plot per-class ROC curves for multiclass\n",
        "            y_val_binarized = pd.get_dummies(y_val_enc)\n",
        "            # compute per-class ROC curves if desired (skipping heavy code here)\n",
        "            print(\"Multiclass ROC curve plotting skipped to keep notebook simple.\")\n",
        "    except Exception as e:\n",
        "        print(\"Could not plot ROC curve:\", e)\n",
        "\n",
        "# -------------------------\n",
        "# GENERATE SUBMISSION (kept logic)\n",
        "# -------------------------\n",
        "print(\"\\n=== Generating submission ===\")\n",
        "test_pred_enc = model_for_submission.predict(test_data_pre)\n",
        "test_pred = le.inverse_transform(test_pred_enc)\n",
        "\n",
        "if test_ids is not None:\n",
        "    submission_df = pd.DataFrame({\n",
        "        ID_COL: test_ids,\n",
        "        TARGET_COL: test_pred\n",
        "    })\n",
        "else:\n",
        "    submission_df = pd.DataFrame({TARGET_COL: test_pred})\n",
        "\n",
        "submission_df.to_csv(OUTPUT_FILE, index=False)\n",
        "print(f\"Submission saved to {OUTPUT_FILE}\")\n",
        "print(submission_df.head())\n",
        "\n",
        "# -------------------------\n",
        "# FINAL NOTES (for your rubric)\n",
        "# -------------------------\n",
        "print(\"\\n=== Rubric mapping summary ===\")\n",
        "print(\"Data Cleaning and Preprocessing: ADDED (duplicates, missing, imputation, documented).\")\n",
        "print(\"Data Visualization and Outlier Analysis: ADDED (histograms, boxplots, corr heatmap, IQR summary).\")\n",
        "print(\"Model Training: Present (baseline RF as before).\")\n",
        "print(\"Hyperparameter Tuning: ADDED (RandomizedSearchCV) â€” optional and compared to baseline.\")\n",
        "print(\"Kaggle Submission: Preserved (same format and logic as your original script).\")\n"
      ]
    }
  ]
}