{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teXkTkr-XwC7"
      },
      "outputs": [],
      "source": [
        "# ===========================================================\n",
        "# IMPORT LIBRARIES\n",
        "# ===========================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "\n",
        "# ===========================================================\n",
        "# LOAD DATA\n",
        "# ===========================================================\n",
        "train = pd.read_csv(\"/kaggle/input/ai-201-b-mse-2-ai-c/train.csv\")\n",
        "test  = pd.read_csv(\"/kaggle/input/ai-201-b-mse-2-ai-c/test.csv\")\n",
        "\n",
        "# ===========================================================\n",
        "# EXTRACT TRAIN IDS\n",
        "# (Not required unless needed for merging, keeping for clarity)\n",
        "# ===========================================================\n",
        "# train_ids = train['id']   # <-- train has no id, so skipping\n",
        "\n",
        "# ===========================================================\n",
        "# TARGET COLUMN\n",
        "# ===========================================================\n",
        "target = \"NObeyesdad\"\n",
        "\n",
        "# ===========================================================\n",
        "# SPLIT FEATURES & TARGET\n",
        "# ===========================================================\n",
        "X = train.drop(columns=[target])\n",
        "y = train[target]\n",
        "\n",
        "# ===========================================================\n",
        "# TRAIN-VALIDATION SPLIT\n",
        "# ===========================================================\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ===========================================================\n",
        "# IDENTIFY NUMERIC & CATEGORICAL COLUMNS\n",
        "# ===========================================================\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# ===========================================================\n",
        "# PREPROCESSING PIPELINES\n",
        "# ===========================================================\n",
        "# Numeric: fill missing with median + scale\n",
        "numeric_pipeline = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "# Categorical: fill missing with mode + OneHotEncoding\n",
        "categorical_pipeline = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "# Combine both pipelines\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    (\"num\", numeric_pipeline, numeric_features),\n",
        "    (\"cat\", categorical_pipeline, categorical_features)\n",
        "])\n",
        "\n",
        "# ===========================================================\n",
        "# LABEL ENCODER FOR TARGET (STRING → NUMBER)\n",
        "# ===========================================================\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_val_enc = le.transform(y_val)\n",
        "\n",
        "# ===========================================================\n",
        "# MODEL\n",
        "# ===========================================================\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    min_samples_split=6,\n",
        "    min_samples_leaf=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# ===========================================================\n",
        "# FINAL PIPELINE (PREPROCESSOR + MODEL)\n",
        "# ===========================================================\n",
        "pipeline = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"classifier\", model)\n",
        "])\n",
        "\n",
        "# ===========================================================\n",
        "# TRAIN MODEL\n",
        "# ===========================================================\n",
        "pipeline.fit(X_train, y_train_enc)\n",
        "\n",
        "# ===========================================================\n",
        "# VALIDATION PREDICTIONS\n",
        "# ===========================================================\n",
        "y_pred = pipeline.predict(X_val)\n",
        "y_pred_proba = pipeline.predict_proba(X_val)\n",
        "\n",
        "# Convert numeric predictions → actual class names\n",
        "y_pred_labels = le.inverse_transform(y_pred)\n",
        "y_val_labels = le.inverse_transform(y_val_enc)\n",
        "\n",
        "# ===========================================================\n",
        "# MODEL PERFORMANCE METRICS\n",
        "# ===========================================================\n",
        "print(\"=========== MODEL PERFORMANCE ===========\")\n",
        "print(\"Accuracy Score:\", accuracy_score(y_val_enc, y_pred))\n",
        "print(\"Precision (Macro):\", precision_score(y_val_labels, y_pred_labels, average='macro'))\n",
        "print(\"Recall (Macro):\", recall_score(y_val_labels, y_pred_labels, average='macro'))\n",
        "print(\"F1-score (Macro):\", f1_score(y_val_labels, y_pred_labels, average='macro'))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_val_enc, y_pred_proba, multi_class='ovr'))\n",
        "print(\"========================================\")\n",
        "\n",
        "# ===========================================================\n",
        "# PREPARE TEST DATA\n",
        "# (Same preprocessing: NO column dropping)\n",
        "# ===========================================================\n",
        "test_ids = test[\"id\"]\n",
        "test_features = test.drop(columns=[\"id\"])\n",
        "\n",
        "# ===========================================================\n",
        "# PREDICT ON TEST SET\n",
        "# ===========================================================\n",
        "test_pred = pipeline.predict(test_features)\n",
        "test_pred_labels = le.inverse_transform(test_pred)\n",
        "\n",
        "# ===========================================================\n",
        "# CREATE SUBMISSION FILE\n",
        "# ===========================================================\n",
        "submission = pd.DataFrame({\n",
        "    \"id\": test_ids,\n",
        "    \"NObeyesdad\": test_pred_labels\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"submission.csv saved successfully!\")"
      ]
    }
  ]
}